#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ä¸€é”®ä¿®å¤è„šæœ¬ - è‡ªåŠ¨è§£å†³GitHub Actionså’Œé…ç½®é—®é¢˜
"""

import os
import json
import yaml
import logging
from pathlib import Path

# è®¾ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

def create_directories():
    """åˆ›å»ºå¿…éœ€çš„ç›®å½•"""
    directories = ['docs', 'pdf_analysis']
    for dir_name in directories:
        Path(dir_name).mkdir(exist_ok=True)
        logger.info(f"âœ… ç›®å½•å·²åˆ›å»º: {dir_name}")

def create_json_files():
    """åˆ›å»ºå¿…éœ€çš„JSONæ–‡ä»¶"""
    json_files = [
        'docs/video-generation-arxiv-daily.json',
        'docs/video-generation-arxiv-daily-web.json', 
        'docs/video-generation-arxiv-daily-wechat.json'
    ]
    
    empty_data = {
        "papers": [],
        "updated": "",
        "total": 0
    }
    
    for json_file in json_files:
        if not os.path.exists(json_file):
            with open(json_file, 'w', encoding='utf-8') as f:
                json.dump(empty_data, f, indent=2, ensure_ascii=False)
            logger.info(f"âœ… JSONæ–‡ä»¶å·²åˆ›å»º: {json_file}")
        else:
            logger.info(f"ğŸ“„ JSONæ–‡ä»¶å·²å­˜åœ¨: {json_file}")

def create_trend_file():
    """åˆ›å»ºè¶‹åŠ¿åˆ†ææ–‡ä»¶"""
    trend_file = 'pdf_analysis/recent_trends.txt'
    if not os.path.exists(trend_file):
        with open(trend_file, 'w', encoding='utf-8') as f:
            f.write("è§†é¢‘ç”Ÿæˆé¢†åŸŸæœ€æ–°è¶‹åŠ¿åˆ†æ\n")
            f.write("=" * 30 + "\n\n")
            f.write("ğŸ“Š å½“å‰è¶‹åŠ¿æ¦‚è§ˆï¼š\n\n")
            f.write("1. Text-to-Videoç”ŸæˆæŠ€æœ¯å¿«é€Ÿå‘å±•\n")
            f.write("2. æ‰©æ•£æ¨¡å‹åœ¨è§†é¢‘ç”Ÿæˆä¸­çš„åº”ç”¨æ—¥ç›Šæˆç†Ÿ\n")
            f.write("3. å¤šæ¨¡æ€è§†é¢‘ç†è§£å’Œæ§åˆ¶æŠ€æœ¯å…´èµ·\n")
            f.write("4. 3Dæ„ŸçŸ¥è§†é¢‘ç”Ÿæˆæˆä¸ºæ–°çƒ­ç‚¹\n")
            f.write("5. è§†é¢‘ç¼–è¾‘å’Œå¢å¼ºæŠ€æœ¯ä¸æ–­ä¼˜åŒ–\n\n")
            f.write("ğŸ’¡ æŠ€æœ¯å‘å±•æ–¹å‘ï¼š\n")
            f.write("- æ›´é«˜è´¨é‡çš„è§†é¢‘ç”Ÿæˆ\n")
            f.write("- æ›´ç²¾ç¡®çš„è¿åŠ¨æ§åˆ¶\n")
            f.write("- æ›´å¥½çš„æ—¶é—´ä¸€è‡´æ€§\n")
            f.write("- æ›´å¼ºçš„å¯æ§æ€§å’Œå¯ç¼–è¾‘æ€§\n\n")
            f.write("æœ¬åˆ†æå°†å®šæœŸæ›´æ–°ï¼Œåæ˜ æœ€æ–°çš„ç ”ç©¶è¶‹åŠ¿å’ŒæŠ€æœ¯è¿›å±•ã€‚\n")
        logger.info(f"âœ… è¶‹åŠ¿æ–‡ä»¶å·²åˆ›å»º: {trend_file}")
    else:
        logger.info(f"ğŸ“„ è¶‹åŠ¿æ–‡ä»¶å·²å­˜åœ¨: {trend_file}")

def rename_old_files():
    """é‡å‘½åæ—§çš„æ–‡ä»¶"""
    file_mappings = {
        'docs/cv-arxiv-daily.json': 'docs/video-generation-arxiv-daily.json',
        'docs/cv-arxiv-daily-web.json': 'docs/video-generation-arxiv-daily-web.json',
        'docs/cv-arxiv-daily-wechat.json': 'docs/video-generation-arxiv-daily-wechat.json'
    }
    
    for old_file, new_file in file_mappings.items():
        if os.path.exists(old_file) and not os.path.exists(new_file):
            os.rename(old_file, new_file)
            logger.info(f"âœ… æ–‡ä»¶å·²é‡å‘½å: {old_file} -> {new_file}")

def check_config_file():
    """æ£€æŸ¥å¹¶éªŒè¯é…ç½®æ–‡ä»¶"""
    config_file = 'config.yaml'
    if not os.path.exists(config_file):
        logger.error(f"âŒ é…ç½®æ–‡ä»¶ä¸å­˜åœ¨: {config_file}")
        return False
    
    try:
        with open(config_file, 'r', encoding='utf-8') as f:
            config = yaml.safe_load(f)
        
        # æ£€æŸ¥å¿…éœ€çš„é…ç½®é¡¹
        required_keys = ['user_name', 'repo_name', 'keywords']
        for key in required_keys:
            if key not in config:
                logger.warning(f"âš ï¸ é…ç½®æ–‡ä»¶ç¼ºå°‘å¿…éœ€é¡¹: {key}")
        
        logger.info("âœ… é…ç½®æ–‡ä»¶æ£€æŸ¥é€šè¿‡")
        return True
    except Exception as e:
        logger.error(f"âŒ é…ç½®æ–‡ä»¶è§£æé”™è¯¯: {e}")
        return False

def create_blacklist_file():
    """åˆ›å»ºé»‘åå•æ–‡ä»¶"""
    blacklist_file = 'blacklists.txt'
    if not os.path.exists(blacklist_file):
        blacklist_content = """# è§†é¢‘ç”Ÿæˆé¢†åŸŸé»‘åå•å…³é”®è¯
# ç”¨äºè¿‡æ»¤ä¸ç›¸å…³çš„è®ºæ–‡

# ä¸ç›¸å…³çš„è®¡ç®—æœºè§†è§‰ä»»åŠ¡
image classification
object detection
semantic segmentation
instance segmentation
face recognition
pose estimation
optical character recognition
medical imaging
satellite imagery

# ä¸ç›¸å…³çš„æœºå™¨å­¦ä¹ ä»»åŠ¡
natural language processing
speech recognition
recommendation system
time series forecasting
tabular data analysis
graph neural network
reinforcement learning games

# ç¡¬ä»¶å’Œç³»ç»Ÿç›¸å…³
hardware acceleration
fpga implementation
mobile deployment
edge computing optimization
network compression
model quantization

# å…¶ä»–ä¸ç›¸å…³é¢†åŸŸ
bioinformatics
financial modeling
weather prediction
autonomous driving sensors
robotics manipulation
"""
        with open(blacklist_file, 'w', encoding='utf-8') as f:
            f.write(blacklist_content)
        logger.info(f"âœ… é»‘åå•æ–‡ä»¶å·²åˆ›å»º: {blacklist_file}")
    else:
        logger.info(f"ğŸ“„ é»‘åå•æ–‡ä»¶å·²å­˜åœ¨: {blacklist_file}")

def create_requirements_file():
    """åˆ›å»ºrequirements.txtæ–‡ä»¶"""
    requirements_file = 'requirements.txt'
    if not os.path.exists(requirements_file):
        requirements_content = """requests>=2.28.0
PyYAML>=6.0
feedparser>=6.0.8
arxiv>=1.4.0
openai>=1.0.0
anthropic>=0.7.0
beautifulsoup4>=4.11.0
lxml>=4.9.0
python-dateutil>=2.8.0
tqdm>=4.64.0
"""
        with open(requirements_file, 'w', encoding='utf-8') as f:
            f.write(requirements_content)
        logger.info(f"âœ… ä¾èµ–æ–‡ä»¶å·²åˆ›å»º: {requirements_file}")
    else:
        logger.info(f"ğŸ“„ ä¾èµ–æ–‡ä»¶å·²å­˜åœ¨: {requirements_file}")

def create_gitignore():
    """åˆ›å»º.gitignoreæ–‡ä»¶"""
    gitignore_file = '.gitignore'
    gitignore_content = """# Python
__pycache__/
*.py[cod]
*$py.class
*.so
.Python
build/
develop-eggs/
dist/
downloads/
eggs/
.eggs/
lib/
lib64/
parts/
sdist/
var/
wheels/
*.egg-info/
.installed.cfg
*.egg

# Virtual Environment
venv/
env/
ENV/

# IDE
.vscode/
.idea/
*.swp
*.swo
*~

# OS
.DS_Store
Thumbs.db

# Logs
*.log
logs/

# API Keys (é‡è¦ï¼šä¿æŠ¤APIå¯†é’¥)
.env
api_keys.txt
secrets.yaml

# Temporary files
temp/
tmp/
*.tmp
"""
    
    if not os.path.exists(gitignore_file):
        with open(gitignore_file, 'w', encoding='utf-8') as f:
            f.write(gitignore_content)
        logger.info(f"âœ… .gitignoreæ–‡ä»¶å·²åˆ›å»º: {gitignore_file}")
    else:
        logger.info(f"ğŸ“„ .gitignoreæ–‡ä»¶å·²å­˜åœ¨: {gitignore_file}")

def verify_fix():
    """éªŒè¯ä¿®å¤ç»“æœ"""
    logger.info("ğŸ” éªŒè¯ä¿®å¤ç»“æœ...")
    
    # æ£€æŸ¥å¿…éœ€æ–‡ä»¶
    required_files = [
        'config.yaml',
        'daily_arxiv.py',
        'docs/video-generation-arxiv-daily.json',
        'docs/video-generation-arxiv-daily-web.json',
        'docs/video-generation-arxiv-daily-wechat.json',
        'pdf_analysis/recent_trends.txt',
        'blacklists.txt',
        'requirements.txt'
    ]
    
    missing_files = []
    for file_path in required_files:
        if not os.path.exists(file_path):
            missing_files.append(file_path)
    
    if missing_files:
        logger.warning(f"âš ï¸ ä»ç¼ºå°‘æ–‡ä»¶: {missing_files}")
        return False
    else:
        logger.info("âœ… æ‰€æœ‰å¿…éœ€æ–‡ä»¶éƒ½å­˜åœ¨")
        return True

def main():
    """ä¸»å‡½æ•°"""
    logger.info("ğŸš€ å¼€å§‹ä¸€é”®ä¿®å¤é¡¹ç›®...")
    
    try:
        # 1. åˆ›å»ºç›®å½•
        create_directories()
        
        # 2. é‡å‘½åæ—§æ–‡ä»¶
        rename_old_files()
        
        # 3. åˆ›å»ºJSONæ–‡ä»¶
        create_json_files()
        
        # 4. åˆ›å»ºè¶‹åŠ¿æ–‡ä»¶
        create_trend_file()
        
        # 5. åˆ›å»ºé»‘åå•æ–‡ä»¶
        create_blacklist_file()
        
        # 6. åˆ›å»ºä¾èµ–æ–‡ä»¶
        create_requirements_file()
        
        # 7. åˆ›å»º.gitignore
        create_gitignore()
        
        # 8. æ£€æŸ¥é…ç½®æ–‡ä»¶
        config_valid = check_config_file()
        
        # 9. éªŒè¯ä¿®å¤ç»“æœ
        fix_successful = verify_fix()
        
        if fix_successful and config_valid:
            logger.info("ğŸ‰ é¡¹ç›®ä¿®å¤å®Œæˆï¼")
            logger.info("ğŸ“‹ æ¥ä¸‹æ¥çš„æ­¥éª¤ï¼š")
            logger.info("   1. è¿è¡Œ: python quick_test.py")
            logger.info("   2. è¿è¡Œ: python daily_arxiv.py")
            logger.info("   3. æäº¤ä»£ç : git add . && git commit -m 'Fix project configuration'")
            logger.info("   4. æ¨é€ä»£ç : git push origin main")
        else:
            logger.warning("âš ï¸ ä¿®å¤è¿‡ç¨‹ä¸­å‘ç°é—®é¢˜ï¼Œè¯·æ£€æŸ¥ä¸Šé¢çš„è­¦å‘Šä¿¡æ¯")
            
    except Exception as e:
        logger.error(f"âŒ ä¿®å¤è¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {e}")
        return False
    
    return True

if __name__ == "__main__":
    success = main()
    exit(0 if success else 1) 